# AI 面试题总结（含 MCP 原理）

> 覆盖机器学习基础、深度学习与架构、LLM 与对齐、推理优化、RAG、评估与安全、MLOps 与数据工程、场景题与动手题；单独包含 Model Context Protocol（MCP）原理与落地细节。

## 目录
- [机器学习基础](#机器学习基础)
- [深度学习与架构](#深度学习与架构)
- [LLM 与对齐](#llm-与对齐)
- [推理与性能优化](#推理与性能优化)
- [RAG（检索增强生成）](#rag检索增强生成)
- [评估与可观测性](#评估与可观测性)
- [安全与合规](#安全与合规)
- [MLOps 与数据工程](#mlops-与数据工程)
- [常见场景题](#常见场景题)
- [动手题](#动手题)
- [MCP 原理（Model Context Protocol）](#mcp-原理model-context-protocol)
- [术语速查](#术语速查)
- [加分题思路](#加分题思路)

---

## 机器学习基础
- 学习范式：监督/无监督/半监督/强化学习，数据需求与适用任务差异。
- 偏差-方差权衡：过拟合、欠拟合；正则化（L2、Dropout、早停）。
- 指标选择：分类（Accuracy、Precision、Recall、F1、ROC-AUC）、回归（MSE、MAE、R²）。
- 数据质量：缺失/异常值处理、类别不平衡（重采样/代价敏感）、数据漂移与再训练触发。

## 深度学习与架构
- 模型家族：CNN（局部感受野/权重共享）、RNN（序列依赖）、Transformer（注意力与并行）。
- 注意力机制：Self/Cross/Multi-Head；缩放点积注意力与掩码；稀疏注意力策略。
- 位置编码：绝对/相对/旋转（RoPE）；长上下文策略（分块、滑窗、线性注意力）。
- 训练优化：优化器（SGD、Adam、AdamW）、学习率调度（Warmup/余弦退火）、梯度裁剪与混合精度（FP16/BF16）。

## LLM 与对齐
- 训练与微调：预训练→SFT；轻量化微调（LoRA、Adapter、Prefix/Prompt Tuning）取舍与适配场景。
- 对齐方法：RLHF（PPO）与 DPO/ORPO 的差异、数据质量要求与可扩展性。
- 指令遵循：系统提示设计、结构化输出（JSON Schema）、函数调用（Tool Use）与多步推理（CoT/ToT）。
- 多语言与领域适配：路由、术语一致性、数据覆盖与评估基线。

## 推理与性能优化
- 并行与缓存：张量并行/流水线并行、KV Cache、PagedAttention、FlashAttention。
- 量化与蒸馏：INT8/INT4、GPTQ/AWQ、SmoothQuant；学生模型蒸馏降低时延与成本。
- 服务化策略：批处理、并发与排队、弹性伸缩；多租户隔离与容量规划。
- 内存管理：长上下文 KV 膨胀控制；分段检索与滑窗生成降低峰值内存。

## RAG（检索增强生成）
- 嵌入与向量库：嵌入模型选型（多语言/领域）、向量库（FAISS、Milvus、PGVector）。
- 切片与索引：语义分块、窗口重叠、元信息（来源/时间/权限）；构建倒排索引与向量混合检索。
- 检索策略：Top-k、MMR、Hybrid（BM25+向量）、元数据过滤；重排序（Cross-Encoder）。
- 上下文注入：模板化提示、引用与证据链；防幻觉与引用置信度校验。
- 在线/动态 RAG：个性化检索、时效性与缓存；检索失败兜底。

## 评估与可观测性
- 评估指标：任务正确率、覆盖率、引用准确率、毒性/偏见、安全性；业务特定指标。
- 自动/人工评估：Rubric 打分器、基准（MMLU、MT-Bench）、自定义任务集与抽样复核。
- 线上监控：延迟、吞吐、错误率、拒答率、上下文长度、Token 成本；告警与回溯。
- 失效模式：幻觉、指令偏离、工具调用失败、检索落空；根因分析与缓解。

## 安全与合规
- 数据隐私：PII 检测与脱敏、数据驻留、访问控制与审计。
- 安全对齐：提示注入/越权/越狱防护；输入净化与上下文隔离；输出审核与拒答策略。
- 供应链安全：模型/嵌入/依赖签名与 SBOM；第三方服务鉴权与速率限制。
- 政策合规：内容审核（Toxicity、Violence、Self-Harm），可观测与封禁策略。

## MLOps 与数据工程
- 数据流水线：采集→标注→质检→分布控制→训练集构建→版本管理（DVC/LakeFS）。
- 分布式训练：DDP、FSDP、ZeRO；断点续训与容错；超参搜索。
- 实验管理：可复现实验、模型/数据/代码版本化；指标与可视化（MLflow/W&B）。
- 部署与发布：边缘/云推理；灰度与回滚；模型分发与热加载；A/B 与多臂老虎机。

## 常见场景题
- 幻觉率偏高：定位检索缺失、指令设计、模型能力与数据噪声；逐步缓解策略。
- 指令遵循差：SFT 数据质量、系统提示、结构化约束（JSON）、对齐方法选择与复盘。
- 成本飙升：长上下文使用分析、KV 缓存策略、量化/蒸馏、批处理与合并请求。
- 多语言支持：嵌入与主模型选型、语言路由、翻译 RAG 与评估基线。
- 工具调用失败：函数模式设计、参数提取鲁棒、重试/回退、工具健康监控与审计。

## 动手题
- 设计 RAG 系统：分块策略、索引、检索与重排序、提示模板、引用防幻觉机制。
- 评估方案：任务集构建、Rubric、自动评分器与抽样人工复核；上线后监控指标。
- 量化与蒸馏：给出延迟与内存预算，选择量化/蒸馏路径并预估效果与风险。
- 工具化 LLM：定义 2–3 个工具函数的模式、容错与安全策略；多轮工具调用链路。

## MCP 原理（Model Context Protocol）
- 核心目标：标准化 LLM 客户端与“上下文服务器（工具/资源/知识库/存储/Prompts）”之间的通信，统一能力发现、调用、权限、流式结果与事件，解耦模型提供方与工具生态。
- 角色与组件：
  - 客户端（LLM 前端/IDE/Agent 框架）：建立连接、发现能力、发起调用、渲染结果。
  - MCP 服务端：暴露能力集合（Tools、Resources、Prompts、Servers），处理请求、流式返回、权限控制与审计。
- 能力模型：
  - Tools：可调用函数，定义名称、输入/输出模式、超时与副作用标识。
  - Resources：可读取的上下文实体（文件、文档、数据库查询、HTTP 资源），支持分页与片段读取。
  - Prompts：预定义提示模板与参数，便于一致化与复用。
  - Servers：可进一步嵌套的后端或子系统能力入口。
- 交互流程：
  - 握手与发现：客户端连接后查询服务端能力元数据（列表、Schema、权限需求、版本）。
  - 调用与流式返回：客户端请求 Tool/Resource/Prompt，服务端执行并以事件流（分段/令牌/状态）返回；支持取消与超时。
  - 权限与确认：敏感能力需要用户同意或策略放行；支持“软拒绝/硬拒绝”与审计日志。
  - 错误与恢复：标准化错误码与重试建议；退避与降级策略。
- 安全与隔离：最小权限（能力级作用域，如只读目录）、限流与配额、输入/输出净化；内容与数据合规的策略执行点在服务端。
- 设计取舍与优势：相较私有函数调用协议，MCP 更通用、跨平台、可扩展；将检索、知识库、外部 API 以统一接口暴露，便于动态上下文注入与治理。
- 示例能力声明（示意）：
```json
{
  "tools": [
    {
      "name": "search_documents",
      "input_schema": {"type": "object", "properties": {"query": {"type": "string"}, "top_k": {"type": "integer"}}},
      "output_schema": {"type": "array", "items": {"type": "object", "properties": {"id": {"type": "string"}, "snippet": {"type": "string"}}}},
      "timeout_ms": 3000,
      "side_effects": false
    }
  ],
  "resources": [
    {
      "name": "docs_corpus",
      "type": "vector_store",
      "read": {"supports_paging": true, "max_page_size": 50}
    }
  ],
  "prompts": [
    {
      "name": "qa_with_citations",
      "params": ["question", "contexts"],
      "version": "1.0"
    }
  ],
  "version": "2024.1"
}
```
- 典型追问与回答要点：
  - 长上下文与流式输出：事件流承载分段结果，客户端边渲染边决策；结合分片读取的 Resource 减少一次性注入。
  - 提示注入与权限：服务端在执行前进行策略校验与参数白名单；客户端将系统提示与工具权限分层隔离。
  - 能力发现与版本管理：能力元数据含版本与兼容信息；客户端按能力特征路由与降级。

## 术语速查
- KV Cache：自回归推理中缓存键值，降低后续步计算成本。
- LoRA/Adapter：低秩更新与模块化微调，降低训练参数与开销。
- DPO/ORPO：基于偏好数据的直接优化，无需环境交互，稳定性好。
- FlashAttention：重写注意力计算以提升吞吐与显存效率。
- Hybrid Search：关键词检索与向量检索结合，兼顾可检索性与语义性。

## 加分题思路
- 基于 MCP 的 RAG Agent：MCP 暴露 `SearchDocuments` 资源与 `Summarize` 工具；客户端按 查询→检索→重排→注入→生成 管线执行，并以策略限制外部调用范围与速率。
- 工具化成功率评估：工具调用正确率、重试率、失败原因分布；基于审计日志构建自动化报表与告警。

---

如果你需要我将这份总结保存为精简版或附带示例答案版，请告诉我偏好主题与长度，我可以生成对应版本。